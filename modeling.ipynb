{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858970a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrangle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "# modeling methods\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "from pydataset import data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math\n",
    "import feature_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data('urine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843148a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.osmo = df.osmo.fillna(df.osmo.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cond = df.cond.fillna(df.cond.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5913136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train, validate, test = feature_selection.split(df, stratify_by=\"urea\")\n",
    "\n",
    "# Setup X and y\n",
    "X_train = train.drop(columns='urea')\n",
    "y_train = train.urea\n",
    "\n",
    "X_validate = validate.drop(columns='urea')\n",
    "y_validate = validate.urea\n",
    "\n",
    "X_test = test.drop(columns='urea')\n",
    "y_test = test.urea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2854a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Use the scaler to transform train, validate, test\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_validate_scaled = scaler.transform(X_validate)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Turn everything into a dataframe\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_validate_scaled = pd.DataFrame(X_validate_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eca11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d4776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 3 features using kbest\n",
    "feature_selection.select_kbest(X_train_scaled, y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6da4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 3 features using RFE\n",
    "selected_features, all_rankings = feature_selection.select_rfe(X_train, y_train, 3)\n",
    "print(selected_features)\n",
    "all_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000c5dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need y_train and y_validate to be dataframes to append the new columns with predicted values. \n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_validate = pd.DataFrame(y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Predict urea_pred_mean\n",
    "urea_pred_mean = y_train.urea.mean()\n",
    "y_train['urea_pred_mean'] = urea_pred_mean\n",
    "y_validate['urea_pred_mean'] = urea_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. compute urea_pred_median\n",
    "urea_pred_median = y_train.urea.median()\n",
    "y_train['urea_pred_median'] = urea_pred_median\n",
    "y_validate['urea_pred_median'] = urea_pred_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. RMSE of urea_pred_mean\n",
    "rmse_train = mean_squared_error(y_train.urea,\n",
    "                                y_train.urea_pred_mean) ** .5\n",
    "rmse_validate = mean_squared_error(y_validate.urea, y_validate.urea_pred_mean) ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28118527",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE using Mean\\nTrain/In-Sample: \", round(rmse_train, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d74a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. RMSE of urea_pred_median\n",
    "rmse_train = mean_squared_error(y_train.urea, y_train.urea_pred_median) ** .5\n",
    "rmse_validate = mean_squared_error(y_validate.urea, y_validate.urea_pred_median) ** .5\n",
    "print(\"RMSE using Median\\nTrain/In-Sample: \", round(rmse_train, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metric_df(y, y_pred, model_name, metric_df):\n",
    "    if metric_df.size ==0:\n",
    "        metric_df = pd.DataFrame(data=[\n",
    "            {\n",
    "                'model': model_name, \n",
    "                'RMSE_validate': mean_squared_error(\n",
    "                    y,\n",
    "                    y_pred) ** .5,\n",
    "                'r^2_validate': explained_variance_score(\n",
    "                    y,\n",
    "                    y_pred)\n",
    "            }])\n",
    "        return metric_df\n",
    "    else:\n",
    "        return metric_df.append(\n",
    "            {\n",
    "                'model': model_name, \n",
    "                'RMSE_validate': mean_squared_error(\n",
    "                    y,\n",
    "                    y_pred) ** .5,\n",
    "                'r^2_validate': explained_variance_score(\n",
    "                    y,\n",
    "                    y_pred)\n",
    "            }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b3c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the metric_df as a blank dataframe\n",
    "metric_df = pd.DataFrame()\n",
    "# make our first entry into the metric_df with median baseline\n",
    "metric_df = make_metric_df(y_train.urea,\n",
    "                           y_train.urea_pred_mean,\n",
    "                           'mean_baseline',\n",
    "                          metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db78341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to visualize actual vs predicted. \n",
    "plt.hist(y_train.urea, color='blue', alpha=.5, label=\"Actual urea\")\n",
    "plt.hist(y_train.urea_pred_mean, bins=1, color='red', alpha=.5, rwidth=100, label=\"Predicted urea - Mean\")\n",
    "plt.hist(y_train.urea_pred_median, bins=1, color='orange', alpha=.5, rwidth=100, label=\"Predicted urea - Median\")\n",
    "plt.xlabel(\"Urea Concentration\")\n",
    "plt.ylabel(\"Number of Patients\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75485b29",
   "metadata": {},
   "source": [
    "### LinearRegression (OLS)\n",
    "1. Fit the model using X_train_scaled and the labels from y_train.\n",
    "2. Predict final grade for Providences in training sample using our model (lm).\n",
    "3. Evaluate using RMSE\n",
    "4. Repeat predictions and evaluation for validation.\n",
    "5. Compare RMSE train vs. validation. Overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbb40aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "# \n",
    "# make the thing\n",
    "# \n",
    "lm = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b401bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "# \n",
    "# fit the thing\n",
    "# \n",
    "lm.fit(X_train, y_train.urea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train\n",
    "# \n",
    "# use the thing!\n",
    "# \n",
    "y_train['urea_pred_lm'] = lm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.urea, y_train.urea_pred_lm) ** (1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['urea_pred_lm'] = lm.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.urea, y_validate.urea_pred_lm) ** (1/2)\n",
    "\n",
    "print(\"RMSE for OLS using LinearRegression\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96faff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df.append({\n",
    "    'model': 'OLS Regressor', \n",
    "    'RMSE_validate': rmse_validate,\n",
    "    'r^2_validate': explained_variance_score(y_validate.urea, y_validate.urea_pred_lm)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174100c3",
   "metadata": {},
   "source": [
    "### LassoLars\n",
    "1. Fit the model using X_train_scaled and the labels from y_train.\n",
    "2. Predict final grade for Providences in training sample using our model (lars).\n",
    "3. Evaluate using RMSE\n",
    "4. Repeat predictions and evaluation for validation.\n",
    "5. Compare RMSE train vs. validation. Overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa2e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lars = LassoLars(alpha=1)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series!\n",
    "lars.fit(X_train, y_train.urea)\n",
    "\n",
    "# predict train\n",
    "y_train['urea_pred_lars'] = lars.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.urea, y_train.urea_pred_lars) ** (1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['urea_pred_lars'] = lars.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.urea, y_validate.urea_pred_lars) ** (1/2)\n",
    "\n",
    "print(\"RMSE for Lasso + Lars\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = make_metric_df(y_validate.urea,\n",
    "               y_validate.urea_pred_lars,\n",
    "               'lasso_alpha_1',\n",
    "               metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98562a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeaa8e1",
   "metadata": {},
   "source": [
    "### TweedieRegressor (GLM)\n",
    "1. Fit the model using X_train_scaled and the labels from y_train.\n",
    "2. Predict final grade for Providences in training sample using our model (glm).\n",
    "3. Evaluate using RMSE\n",
    "4. Repeat predictions and evaluation for validation.\n",
    "5. Compare RMSE train vs. validation. Overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60429da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import TweedieRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da207ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "glm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "glm.fit(X_train, y_train.urea)\n",
    "\n",
    "# predict train\n",
    "y_train['urea_pred_glm'] = glm.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.urea, y_train.urea_pred_glm) ** (1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['urea_pred_glm'] = glm.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.urea, y_validate.urea_pred_glm) ** (1/2)\n",
    "\n",
    "print(\"RMSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd36a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = make_metric_df(y_validate.urea,\n",
    "               y_validate.urea_pred_glm,\n",
    "               'glm_poisson',\n",
    "               metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d3d1b",
   "metadata": {},
   "source": [
    "### Polynomial Regression\n",
    "Using sklearn.preprocessing.PolynommialFeatures() + sklearn.linear_model.LinearRegression()\n",
    "1. Create the new features, based on value indicated for degree for train, validate & test.\n",
    "2. Fit the Linear Regression model\n",
    "3. Predict using the transformed (squared or cubed, e.g.) features\n",
    "4. Evaluate using RMSE\n",
    "5. Repeat predictions and evaluation for validation.\n",
    "6. Compare RMSE train vs. validation. Overfitting?\n",
    "\n",
    "*****************************************************\n",
    "## PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd3de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree2 = pf.fit_transform(X_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree2 = pf.transform(X_validate)\n",
    "X_test_degree2 =  pf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae36c492",
   "metadata": {},
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm2.fit(X_train_degree2, y_train.urea)\n",
    "\n",
    "# predict train\n",
    "y_train['urea_pred_lm2'] = lm2.predict(X_train_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.urea, y_train.urea_pred_lm2) ** (1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['urea_pred_lm2'] = lm2.predict(X_validate_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.urea, y_validate.urea_pred_lm2) ** 0.5\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b46204",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = make_metric_df(y_validate.urea,\n",
    "               y_validate.urea_pred_lm2,\n",
    "               'quadratic',\n",
    "               metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375747de",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af021752",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "Plotting Actual vs. Predicted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate.urea, y_validate.urea_pred_mean, alpha=.5, color=\"gray\", label='_nolegend_')\n",
    "plt.plot(y_validate.urea, y_validate.urea, alpha=.5, color=\"blue\", label='_nolegend_')\n",
    "\n",
    "plt.scatter(y_validate.urea, y_validate.urea_pred_lm, \n",
    "            alpha=.5, color=\"red\", s=100, label=\"Model: LinearRegression\")\n",
    "plt.scatter(y_validate.urea, y_validate.urea_pred_glm, \n",
    "            alpha=.5, color=\"yellow\", s=100, label=\"Model: TweedieRegressor\")\n",
    "plt.scatter(y_validate.urea, y_validate.urea_pred_lm2, \n",
    "            alpha=.5, color=\"green\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual urea Concentration\")\n",
    "plt.ylabel(\"Predicted Urea Concentration\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991f32a",
   "metadata": {},
   "source": [
    "### Residual Plots: Plotting the Errors in Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f40dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.axhline(label=\"No Error\")\n",
    "plt.scatter(y_validate.urea, y_validate.urea_pred_lm - y_validate.urea , \n",
    "            alpha=.5, color=\"red\", s=100, label=\"Model: LinearRegression\")\n",
    "plt.scatter(y_validate.urea, y_validate.urea_pred_glm - y_validate.urea, \n",
    "            alpha=.5, color=\"yellow\", s=100, label=\"Model: TweedieRegressor\")\n",
    "plt.scatter(y_validate.urea, y_validate.urea_pred_lm2 - y_validate.urea, \n",
    "            alpha=.5, color=\"green\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual Urea Concentration\")\n",
    "plt.ylabel(\"Residual/Error: Predicted Concentration - Actual Concentration\")\n",
    "plt.title(\"Do the size of errors change as the actual value changes?\")\n",
    "# plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "# plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13932b",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to visualize actual vs predicted. \n",
    "plt.figure(figsize=(16,8))\n",
    "plt.hist(y_validate.urea, color='blue', alpha=.5, label=\"Actual urea\")\n",
    "plt.hist(y_validate.urea_pred_lm, color='red', alpha=.5, label=\"Model: LinearRegression\")\n",
    "plt.hist(y_validate.urea_pred_glm, color='yellow', alpha=.5, label=\"Model: TweedieRegressor\")\n",
    "plt.hist(y_validate.urea_pred_lm2, color='green', alpha=.5, label=\"Model 2nd degree Polynomial\")\n",
    "plt.xlabel(\"Urea Concentration\")\n",
    "plt.ylabel(\"Number of Patients\")\n",
    "plt.title(\"Comparing the Distribution of Actual Urea Conentrations to Distributions of Predicted Urea Concentrations for the Top Models\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# addendum: Comparing models DF:\n",
    "metric_df[['model', 'RMSE_validate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160a7e06",
   "metadata": {},
   "source": [
    "### Model Selection & Out-of-Sample Evaluation\n",
    "Model selected: lm (using LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "# predict on test\n",
    "y_test['urea_pred_lm'] = lm.predict(X_test)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_test = mean_squared_error(y_test.urea, y_test.urea_pred_lm) ** (1/2)\n",
    "\n",
    "print(\"RMSE for OLS Model using LinearRegression\\nOut-of-Sample Performance: \", rmse_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
